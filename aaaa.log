I0413 21:38:44.887684 10154 caffe.cpp:113] Use GPU with device ID 1
I0413 21:38:45.089387 10154 caffe.cpp:121] Starting Optimization
I0413 21:38:45.089481 10154 solver.cpp:32] Initializing solver from parameters: 
test_iter: 1
test_interval: 1000
base_lr: 0.005
display: 10
max_iter: 60000
lr_policy: "step"
gamma: 0.1
momentum: 0.9
weight_decay: 0.0005
stepsize: 20000
snapshot: 5000
snapshot_prefix: "./examples/sum_layer_debug/cache/lsp"
solver_mode: GPU
net: "./examples/sum_layer_debug/lsp_train_val.prototxt"
I0413 21:38:45.089504 10154 solver.cpp:70] Creating training net from net file: ./examples/sum_layer_debug/lsp_train_val.prototxt
I0413 21:38:45.090102 10154 net.cpp:257] The NetState phase (0) differed from the phase (1) specified by a rule in layer data
I0413 21:38:45.090124 10154 net.cpp:257] The NetState phase (0) differed from the phase (1) specified by a rule in layer accuracy
I0413 21:38:45.090272 10154 net.cpp:42] Initializing net from parameters: 
name: "TrainValNet"
state {
  phase: TRAIN
}
layer {
  name: "data"
  type: "Data"
  top: "data"
  top: "label"
  include {
    phase: TRAIN
  }
  transform_param {
    mirror: false
    mean_value: 128
    mean_value: 128
    mean_value: 128
  }
  data_param {
    source: "/home/wyang/Data/Code/pose/chen_nips14_full/cache/lsp-03-06/LMDB_train"
    batch_size: 2
    backend: LMDB
  }
}
layer {
  name: "conv1"
  type: "Convolution"
  bottom: "data"
  top: "conv1"
  param {
    lr_mult: 1
    decay_mult: 1
  }
  param {
    lr_mult: 2
    decay_mult: 0
  }
  convolution_param {
    num_output: 48
    pad: 2
    kernel_size: 5
    stride: 1
    weight_filler {
      type: "gaussian"
      std: 0.01
    }
    bias_filler {
      type: "constant"
      value: 0
    }
  }
}
layer {
  name: "relu1"
  type: "ReLU"
  bottom: "conv1"
  top: "conv1"
}
layer {
  name: "pool1"
  type: "Pooling"
  bottom: "conv1"
  top: "pool1"
  pooling_param {
    pool: MAX
    kernel_size: 3
    stride: 2
  }
}
layer {
  name: "norm1"
  type: "LRN"
  bottom: "pool1"
  top: "norm1"
  lrn_param {
    local_size: 5
    alpha: 0.0001
    beta: 0.75
  }
}
layer {
  name: "conv2"
  type: "Convolution"
  bottom: "norm1"
  top: "conv2"
  param {
    lr_mult: 1
    decay_mult: 1
  }
  param {
    lr_mult: 2
    decay_mult: 0
  }
  convolution_param {
    num_output: 128
    pad: 1
    kernel_size: 3
    stride: 1
    weight_filler {
      type: "gaussian"
      std: 0.01
    }
    bias_filler {
      type: "constant"
      value: 1
    }
  }
}
layer {
  name: "relu2"
  type: "ReLU"
  bottom: "conv2"
  top: "conv2"
}
layer {
  name: "pool2"
  type: "Pooling"
  bottom: "conv2"
  top: "pool2"
  pooling_param {
    pool: MAX
    kernel_size: 3
    stride: 2
  }
}
layer {
  name: "norm2"
  type: "LRN"
  bottom: "pool2"
  top: "norm2"
  lrn_param {
    local_size: 5
    alpha: 0.0001
    beta: 0.75
  }
}
layer {
  name: "conv3"
  type: "Convolution"
  bottom: "norm2"
  top: "conv3"
  param {
    lr_mult: 1
    decay_mult: 1
  }
  param {
    lr_mult: 2
    decay_mult: 0
  }
  convolution_param {
    num_output: 128
    pad: 1
    kernel_size: 3
    stride: 1
    weight_filler {
      type: "gaussian"
      std: 0.01
    }
    bias_filler {
      type: "constant"
      value: 1
    }
  }
}
layer {
  name: "relu3"
  type: "ReLU"
  bottom: "conv3"
  top: "conv3"
}
layer {
  name: "conv4"
  type: "Convolution"
  bottom: "conv3"
  top: "conv4"
  param {
    lr_mult: 1
    decay_mult: 1
  }
  param {
    lr_mult: 2
    decay_mult: 0
  }
  convolution_param {
    num_output: 128
    pad: 1
    kernel_size: 3
    stride: 1
    weight_filler {
      type: "gaussian"
      std: 0.01
    }
    bias_filler {
      type: "constant"
      value: 1
    }
  }
}
layer {
  name: "relu4"
  type: "ReLU"
  bottom: "conv4"
  top: "conv4"
}
layer {
  name: "conv5"
  type: "Convolution"
  bottom: "conv4"
  top: "conv5"
  param {
    lr_mult: 1
    decay_mult: 1
  }
  param {
    lr_mult: 2
    decay_mult: 0
  }
  convolution_param {
    num_output: 128
    pad: 1
    kernel_size: 3
    stride: 1
    weight_filler {
      type: "gaussian"
      std: 0.01
    }
    bias_filler {
      type: "constant"
      value: 1
    }
  }
}
layer {
  name: "relu5"
  type: "ReLU"
  bottom: "conv5"
  top: "conv5"
}
layer {
  name: "fc6-conv"
  type: "Convolution"
  bottom: "conv5"
  top: "fc6-conv"
  param {
    lr_mult: 1
    decay_mult: 1
  }
  param {
    lr_mult: 2
    decay_mult: 0
  }
  convolution_param {
    num_output: 4096
    pad: 0
    kernel_size: 9
    stride: 1
  }
}
layer {
  name: "relu6"
  type: "ReLU"
  bottom: "fc6-conv"
  top: "fc6-conv"
}
layer {
  name: "drop6"
  type: "Dropout"
  bottom: "fc6-conv"
  top: "fc6-conv"
  dropout_param {
    dropout_ratio: 0.5
  }
}
layer {
  name: "fc7-conv"
  type: "Convolution"
  bottom: "fc6-conv"
  top: "fc7-conv"
  param {
    lr_mult: 1
    decay_mult: 1
  }
  param {
    lr_mult: 2
    decay_mult: 0
  }
  convolution_param {
    num_output: 4096
    pad: 0
    kernel_size: 1
    stride: 1
  }
}
layer {
  name: "relu7"
  type: "ReLU"
  bottom: "fc7-conv"
  top: "fc7-conv"
}
layer {
  name: "drop7"
  type: "Dropout"
  bottom: "fc7-conv"
  top: "fc7-conv"
  dropout_param {
    dropout_ratio: 0.5
  }
}
layer {
  name: "fc8-conv"
  type: "Convolution"
  bottom: "fc7-conv"
  top: "fc8-conv"
  param {
    lr_mult: 1
    decay_mult: 1
  }
  param {
    lr_mult: 2
    decay_mult: 0
  }
  convolution_param {
    num_output: 9699
    pad: 0
    kernel_size: 1
    stride: 1
  }
}
layer {
  name: "prob"
  type: "Softmax"
  bottom: "fc8-conv"
  top: "prob"
}
layer {
  name: "unary"
  type: "Sum"
  bottom: "prob"
  top: "unary"
  sum_param {
    source: "/home/wyang/Data/Code/iccv/chen-nips14-pose-dev/global_ids.txt"
    mix_num: 13
    parents: 0
    parents: 1
    parents: 2
    parents: 3
    parents: 4
    parents: 5
    parents: 6
    parents: 3
    parents: 8
    parents: 9
    parents: 10
    parents: 11
    parents: 12
    parents: 13
    parents: 2
    parents: 15
    parents: 16
    parents: 17
    parents: 18
    parents: 15
    parents: 20
    parents: 21
    parents: 22
    parents: 23
    parents: 24
    parents: 25
  }
}
layer {
  name: "unary-silence"
  type: "Silence"
  bottom: "unary"
}
layer {
  name: "idpr"
  type: "Idpr"
  bottom: "prob"
  top: "idpr"
  sum_param {
    mix_num: 13
    parents: 0
    parents: 1
    parents: 2
    parents: 3
    parents: 4
    parents: 5
    parents: 6
    parents: 3
    parents: 8
    parents: 9
    parents: 10
    parents: 11
    parents: 12
    parents: 13
    parents: 2
    parents: 15
    parents: 16
    parents: 17
    parents: 18
    parents: 15
    parents: 20
    parents: 21
    parents: 22
    parents: 23
    parents: 24
    parents: 25
  }
}
layer {
  name: "logidpr"
  type: "Logarithm"
  bottom: "idpr"
  top: "idpr"
}
layer {
  name: "idpr-silence"
  type: "Silence"
  bottom: "idpr"
}
layer {
  name: "loss"
  type: "SoftmaxWithLoss"
  bottom: "fc8-conv"
  bottom: "label"
  top: "loss"
}
I0413 21:38:45.090412 10154 layer_factory.hpp:74] Creating layer data
I0413 21:38:45.090430 10154 net.cpp:84] Creating Layer data
I0413 21:38:45.090438 10154 net.cpp:338] data -> data
I0413 21:38:45.090459 10154 net.cpp:338] data -> label
I0413 21:38:45.090468 10154 net.cpp:113] Setting up data
I0413 21:38:45.090525 10154 db.cpp:34] Opened lmdb /home/wyang/Data/Code/pose/chen_nips14_full/cache/lsp-03-06/LMDB_train
I0413 21:38:45.090565 10154 data_layer.cpp:67] output data size: 2,3,36,36
I0413 21:38:45.090630 10154 net.cpp:120] Top shape: 2 3 36 36 (7776)
I0413 21:38:45.090636 10154 net.cpp:120] Top shape: 2 (2)
I0413 21:38:45.090641 10154 layer_factory.hpp:74] Creating layer conv1
I0413 21:38:45.090649 10154 net.cpp:84] Creating Layer conv1
I0413 21:38:45.090654 10154 net.cpp:380] conv1 <- data
I0413 21:38:45.090665 10154 net.cpp:338] conv1 -> conv1
I0413 21:38:45.090673 10154 net.cpp:113] Setting up conv1
I0413 21:38:45.091210 10154 net.cpp:120] Top shape: 2 48 36 36 (124416)
I0413 21:38:45.091223 10154 layer_factory.hpp:74] Creating layer relu1
I0413 21:38:45.091230 10154 net.cpp:84] Creating Layer relu1
I0413 21:38:45.091234 10154 net.cpp:380] relu1 <- conv1
I0413 21:38:45.091238 10154 net.cpp:327] relu1 -> conv1 (in-place)
I0413 21:38:45.091243 10154 net.cpp:113] Setting up relu1
I0413 21:38:45.091259 10154 net.cpp:120] Top shape: 2 48 36 36 (124416)
I0413 21:38:45.091262 10154 layer_factory.hpp:74] Creating layer pool1
I0413 21:38:45.091269 10154 net.cpp:84] Creating Layer pool1
I0413 21:38:45.091271 10154 net.cpp:380] pool1 <- conv1
I0413 21:38:45.091275 10154 net.cpp:338] pool1 -> pool1
I0413 21:38:45.091281 10154 net.cpp:113] Setting up pool1
I0413 21:38:45.091291 10154 net.cpp:120] Top shape: 2 48 18 18 (31104)
I0413 21:38:45.091295 10154 layer_factory.hpp:74] Creating layer norm1
I0413 21:38:45.091301 10154 net.cpp:84] Creating Layer norm1
I0413 21:38:45.091305 10154 net.cpp:380] norm1 <- pool1
I0413 21:38:45.091310 10154 net.cpp:338] norm1 -> norm1
I0413 21:38:45.091316 10154 net.cpp:113] Setting up norm1
I0413 21:38:45.091325 10154 net.cpp:120] Top shape: 2 48 18 18 (31104)
I0413 21:38:45.091327 10154 layer_factory.hpp:74] Creating layer conv2
I0413 21:38:45.091331 10154 net.cpp:84] Creating Layer conv2
I0413 21:38:45.091334 10154 net.cpp:380] conv2 <- norm1
I0413 21:38:45.091339 10154 net.cpp:338] conv2 -> conv2
I0413 21:38:45.091344 10154 net.cpp:113] Setting up conv2
I0413 21:38:45.093113 10154 net.cpp:120] Top shape: 2 128 18 18 (82944)
I0413 21:38:45.093144 10154 layer_factory.hpp:74] Creating layer relu2
I0413 21:38:45.093164 10154 net.cpp:84] Creating Layer relu2
I0413 21:38:45.093181 10154 net.cpp:380] relu2 <- conv2
I0413 21:38:45.093189 10154 net.cpp:327] relu2 -> conv2 (in-place)
I0413 21:38:45.093197 10154 net.cpp:113] Setting up relu2
I0413 21:38:45.093204 10154 net.cpp:120] Top shape: 2 128 18 18 (82944)
I0413 21:38:45.093209 10154 layer_factory.hpp:74] Creating layer pool2
I0413 21:38:45.093214 10154 net.cpp:84] Creating Layer pool2
I0413 21:38:45.093219 10154 net.cpp:380] pool2 <- conv2
I0413 21:38:45.093240 10154 net.cpp:338] pool2 -> pool2
I0413 21:38:45.093246 10154 net.cpp:113] Setting up pool2
I0413 21:38:45.093266 10154 net.cpp:120] Top shape: 2 128 9 9 (20736)
I0413 21:38:45.093268 10154 layer_factory.hpp:74] Creating layer norm2
I0413 21:38:45.093276 10154 net.cpp:84] Creating Layer norm2
I0413 21:38:45.093281 10154 net.cpp:380] norm2 <- pool2
I0413 21:38:45.093284 10154 net.cpp:338] norm2 -> norm2
I0413 21:38:45.093289 10154 net.cpp:113] Setting up norm2
I0413 21:38:45.093294 10154 net.cpp:120] Top shape: 2 128 9 9 (20736)
I0413 21:38:45.093297 10154 layer_factory.hpp:74] Creating layer conv3
I0413 21:38:45.093305 10154 net.cpp:84] Creating Layer conv3
I0413 21:38:45.093309 10154 net.cpp:380] conv3 <- norm2
I0413 21:38:45.093313 10154 net.cpp:338] conv3 -> conv3
I0413 21:38:45.093322 10154 net.cpp:113] Setting up conv3
I0413 21:38:45.098220 10154 net.cpp:120] Top shape: 2 128 9 9 (20736)
I0413 21:38:45.098258 10154 layer_factory.hpp:74] Creating layer relu3
I0413 21:38:45.098266 10154 net.cpp:84] Creating Layer relu3
I0413 21:38:45.098271 10154 net.cpp:380] relu3 <- conv3
I0413 21:38:45.098278 10154 net.cpp:327] relu3 -> conv3 (in-place)
I0413 21:38:45.098284 10154 net.cpp:113] Setting up relu3
I0413 21:38:45.098289 10154 net.cpp:120] Top shape: 2 128 9 9 (20736)
I0413 21:38:45.098301 10154 layer_factory.hpp:74] Creating layer conv4
I0413 21:38:45.098309 10154 net.cpp:84] Creating Layer conv4
I0413 21:38:45.098312 10154 net.cpp:380] conv4 <- conv3
I0413 21:38:45.098317 10154 net.cpp:338] conv4 -> conv4
I0413 21:38:45.098323 10154 net.cpp:113] Setting up conv4
I0413 21:38:45.102782 10154 net.cpp:120] Top shape: 2 128 9 9 (20736)
I0413 21:38:45.102807 10154 layer_factory.hpp:74] Creating layer relu4
I0413 21:38:45.102815 10154 net.cpp:84] Creating Layer relu4
I0413 21:38:45.102819 10154 net.cpp:380] relu4 <- conv4
I0413 21:38:45.102836 10154 net.cpp:327] relu4 -> conv4 (in-place)
I0413 21:38:45.102843 10154 net.cpp:113] Setting up relu4
I0413 21:38:45.102849 10154 net.cpp:120] Top shape: 2 128 9 9 (20736)
I0413 21:38:45.102852 10154 layer_factory.hpp:74] Creating layer conv5
I0413 21:38:45.102859 10154 net.cpp:84] Creating Layer conv5
I0413 21:38:45.102861 10154 net.cpp:380] conv5 <- conv4
I0413 21:38:45.102869 10154 net.cpp:338] conv5 -> conv5
I0413 21:38:45.102886 10154 net.cpp:113] Setting up conv5
I0413 21:38:45.108355 10154 net.cpp:120] Top shape: 2 128 9 9 (20736)
I0413 21:38:45.108382 10154 layer_factory.hpp:74] Creating layer relu5
I0413 21:38:45.108391 10154 net.cpp:84] Creating Layer relu5
I0413 21:38:45.108396 10154 net.cpp:380] relu5 <- conv5
I0413 21:38:45.108402 10154 net.cpp:327] relu5 -> conv5 (in-place)
I0413 21:38:45.108407 10154 net.cpp:113] Setting up relu5
I0413 21:38:45.108412 10154 net.cpp:120] Top shape: 2 128 9 9 (20736)
I0413 21:38:45.108415 10154 layer_factory.hpp:74] Creating layer fc6-conv
I0413 21:38:45.108433 10154 net.cpp:84] Creating Layer fc6-conv
I0413 21:38:45.108438 10154 net.cpp:380] fc6-conv <- conv5
I0413 21:38:45.108443 10154 net.cpp:338] fc6-conv -> fc6-conv
I0413 21:38:45.108448 10154 net.cpp:113] Setting up fc6-conv
I0413 21:38:45.155899 10154 net.cpp:120] Top shape: 2 4096 1 1 (8192)
I0413 21:38:45.155931 10154 layer_factory.hpp:74] Creating layer relu6
I0413 21:38:45.155942 10154 net.cpp:84] Creating Layer relu6
I0413 21:38:45.155947 10154 net.cpp:380] relu6 <- fc6-conv
I0413 21:38:45.155963 10154 net.cpp:327] relu6 -> fc6-conv (in-place)
I0413 21:38:45.155971 10154 net.cpp:113] Setting up relu6
I0413 21:38:45.155975 10154 net.cpp:120] Top shape: 2 4096 1 1 (8192)
I0413 21:38:45.155979 10154 layer_factory.hpp:74] Creating layer drop6
I0413 21:38:45.155988 10154 net.cpp:84] Creating Layer drop6
I0413 21:38:45.155992 10154 net.cpp:380] drop6 <- fc6-conv
I0413 21:38:45.155997 10154 net.cpp:327] drop6 -> fc6-conv (in-place)
I0413 21:38:45.156002 10154 net.cpp:113] Setting up drop6
I0413 21:38:45.156011 10154 net.cpp:120] Top shape: 2 4096 1 1 (8192)
I0413 21:38:45.156014 10154 layer_factory.hpp:74] Creating layer fc7-conv
I0413 21:38:45.156020 10154 net.cpp:84] Creating Layer fc7-conv
I0413 21:38:45.156024 10154 net.cpp:380] fc7-conv <- fc6-conv
I0413 21:38:45.156029 10154 net.cpp:338] fc7-conv -> fc7-conv
I0413 21:38:45.156035 10154 net.cpp:113] Setting up fc7-conv
I0413 21:38:45.169106 10154 net.cpp:120] Top shape: 2 4096 1 1 (8192)
I0413 21:38:45.169143 10154 layer_factory.hpp:74] Creating layer relu7
I0413 21:38:45.169158 10154 net.cpp:84] Creating Layer relu7
I0413 21:38:45.169164 10154 net.cpp:380] relu7 <- fc7-conv
I0413 21:38:45.169174 10154 net.cpp:327] relu7 -> fc7-conv (in-place)
I0413 21:38:45.169183 10154 net.cpp:113] Setting up relu7
I0413 21:38:45.169190 10154 net.cpp:120] Top shape: 2 4096 1 1 (8192)
I0413 21:38:45.169194 10154 layer_factory.hpp:74] Creating layer drop7
I0413 21:38:45.169203 10154 net.cpp:84] Creating Layer drop7
I0413 21:38:45.169208 10154 net.cpp:380] drop7 <- fc7-conv
I0413 21:38:45.169214 10154 net.cpp:327] drop7 -> fc7-conv (in-place)
I0413 21:38:45.169220 10154 net.cpp:113] Setting up drop7
I0413 21:38:45.169227 10154 net.cpp:120] Top shape: 2 4096 1 1 (8192)
I0413 21:38:45.169237 10154 layer_factory.hpp:74] Creating layer fc8-conv
I0413 21:38:45.169246 10154 net.cpp:84] Creating Layer fc8-conv
I0413 21:38:45.169253 10154 net.cpp:380] fc8-conv <- fc7-conv
I0413 21:38:45.169260 10154 net.cpp:338] fc8-conv -> fc8-conv
I0413 21:38:45.169268 10154 net.cpp:113] Setting up fc8-conv
I0413 21:38:45.199910 10154 net.cpp:120] Top shape: 2 9699 1 1 (19398)
I0413 21:38:45.199947 10154 layer_factory.hpp:74] Creating layer fc8-conv_fc8-conv_0_split
I0413 21:38:45.199961 10154 net.cpp:84] Creating Layer fc8-conv_fc8-conv_0_split
I0413 21:38:45.199965 10154 net.cpp:380] fc8-conv_fc8-conv_0_split <- fc8-conv
I0413 21:38:45.199985 10154 net.cpp:338] fc8-conv_fc8-conv_0_split -> fc8-conv_fc8-conv_0_split_0
I0413 21:38:45.199993 10154 net.cpp:338] fc8-conv_fc8-conv_0_split -> fc8-conv_fc8-conv_0_split_1
I0413 21:38:45.199998 10154 net.cpp:113] Setting up fc8-conv_fc8-conv_0_split
I0413 21:38:45.200006 10154 net.cpp:120] Top shape: 2 9699 1 1 (19398)
I0413 21:38:45.200011 10154 net.cpp:120] Top shape: 2 9699 1 1 (19398)
I0413 21:38:45.200013 10154 layer_factory.hpp:74] Creating layer prob
I0413 21:38:45.200019 10154 net.cpp:84] Creating Layer prob
I0413 21:38:45.200022 10154 net.cpp:380] prob <- fc8-conv_fc8-conv_0_split_0
I0413 21:38:45.200048 10154 net.cpp:338] prob -> prob
I0413 21:38:45.200057 10154 net.cpp:113] Setting up prob
I0413 21:38:45.200083 10154 net.cpp:120] Top shape: 2 9699 1 1 (19398)
I0413 21:38:45.200096 10154 layer_factory.hpp:74] Creating layer prob_prob_0_split
I0413 21:38:45.200100 10154 net.cpp:84] Creating Layer prob_prob_0_split
I0413 21:38:45.200114 10154 net.cpp:380] prob_prob_0_split <- prob
I0413 21:38:45.200119 10154 net.cpp:338] prob_prob_0_split -> prob_prob_0_split_0
I0413 21:38:45.200134 10154 net.cpp:338] prob_prob_0_split -> prob_prob_0_split_1
I0413 21:38:45.200139 10154 net.cpp:113] Setting up prob_prob_0_split
I0413 21:38:45.200153 10154 net.cpp:120] Top shape: 2 9699 1 1 (19398)
I0413 21:38:45.200157 10154 net.cpp:120] Top shape: 2 9699 1 1 (19398)
I0413 21:38:45.200160 10154 layer_factory.hpp:74] Creating layer unary
I0413 21:38:45.200170 10154 net.cpp:84] Creating Layer unary
I0413 21:38:45.200172 10154 net.cpp:380] unary <- prob_prob_0_split_0
I0413 21:38:45.200178 10154 net.cpp:338] unary -> unary
I0413 21:38:45.200184 10154 net.cpp:113] Setting up unary
I0413 21:38:45.200441 10154 net.cpp:120] Top shape: 2 26 1 1 (52)
I0413 21:38:45.200446 10154 layer_factory.hpp:74] Creating layer unary-silence
I0413 21:38:45.200469 10154 net.cpp:84] Creating Layer unary-silence
I0413 21:38:45.200472 10154 net.cpp:380] unary-silence <- unary
I0413 21:38:45.200486 10154 net.cpp:113] Setting up unary-silence
I0413 21:38:45.200490 10154 layer_factory.hpp:74] Creating layer idpr
I0413 21:38:45.200497 10154 net.cpp:84] Creating Layer idpr
I0413 21:38:45.200500 10154 net.cpp:380] idpr <- prob_prob_0_split_1
I0413 21:38:45.200506 10154 net.cpp:338] idpr -> idpr
I0413 21:38:45.200511 10154 net.cpp:113] Setting up idpr
I0413 21:38:45.201429 10154 net.cpp:120] Top shape: 2 650 1 1 (1300)
I0413 21:38:45.201434 10154 layer_factory.hpp:74] Creating layer logidpr
I0413 21:38:45.201452 10154 net.cpp:84] Creating Layer logidpr
I0413 21:38:45.201454 10154 net.cpp:380] logidpr <- idpr
I0413 21:38:45.201459 10154 net.cpp:327] logidpr -> idpr (in-place)
I0413 21:38:45.201473 10154 net.cpp:113] Setting up logidpr
I0413 21:38:45.201478 10154 net.cpp:120] Top shape: 2 650 1 1 (1300)
I0413 21:38:45.201481 10154 layer_factory.hpp:74] Creating layer idpr-silence
I0413 21:38:45.201485 10154 net.cpp:84] Creating Layer idpr-silence
I0413 21:38:45.201488 10154 net.cpp:380] idpr-silence <- idpr
I0413 21:38:45.201493 10154 net.cpp:113] Setting up idpr-silence
I0413 21:38:45.201495 10154 layer_factory.hpp:74] Creating layer loss
I0413 21:38:45.201501 10154 net.cpp:84] Creating Layer loss
I0413 21:38:45.201504 10154 net.cpp:380] loss <- fc8-conv_fc8-conv_0_split_1
I0413 21:38:45.201508 10154 net.cpp:380] loss <- label
I0413 21:38:45.201514 10154 net.cpp:338] loss -> loss
I0413 21:38:45.201519 10154 net.cpp:113] Setting up loss
I0413 21:38:45.201527 10154 layer_factory.hpp:74] Creating layer loss
I0413 21:38:45.201604 10154 net.cpp:120] Top shape: (1)
I0413 21:38:45.201609 10154 net.cpp:122]     with loss weight 1
I0413 21:38:45.201634 10154 net.cpp:167] loss needs backward computation.
I0413 21:38:45.201648 10154 net.cpp:169] idpr-silence does not need backward computation.
I0413 21:38:45.201652 10154 net.cpp:169] logidpr does not need backward computation.
I0413 21:38:45.201654 10154 net.cpp:169] idpr does not need backward computation.
I0413 21:38:45.201656 10154 net.cpp:169] unary-silence does not need backward computation.
I0413 21:38:45.201659 10154 net.cpp:169] unary does not need backward computation.
I0413 21:38:45.201663 10154 net.cpp:169] prob_prob_0_split does not need backward computation.
I0413 21:38:45.201664 10154 net.cpp:169] prob does not need backward computation.
I0413 21:38:45.201668 10154 net.cpp:167] fc8-conv_fc8-conv_0_split needs backward computation.
I0413 21:38:45.201670 10154 net.cpp:167] fc8-conv needs backward computation.
I0413 21:38:45.201673 10154 net.cpp:167] drop7 needs backward computation.
I0413 21:38:45.201676 10154 net.cpp:167] relu7 needs backward computation.
I0413 21:38:45.201688 10154 net.cpp:167] fc7-conv needs backward computation.
I0413 21:38:45.201690 10154 net.cpp:167] drop6 needs backward computation.
I0413 21:38:45.201694 10154 net.cpp:167] relu6 needs backward computation.
I0413 21:38:45.201696 10154 net.cpp:167] fc6-conv needs backward computation.
I0413 21:38:45.201699 10154 net.cpp:167] relu5 needs backward computation.
I0413 21:38:45.201702 10154 net.cpp:167] conv5 needs backward computation.
I0413 21:38:45.201705 10154 net.cpp:167] relu4 needs backward computation.
I0413 21:38:45.201709 10154 net.cpp:167] conv4 needs backward computation.
I0413 21:38:45.201712 10154 net.cpp:167] relu3 needs backward computation.
I0413 21:38:45.201846 10154 net.cpp:167] conv3 needs backward computation.
I0413 21:38:45.201861 10154 net.cpp:167] norm2 needs backward computation.
I0413 21:38:45.201864 10154 net.cpp:167] pool2 needs backward computation.
I0413 21:38:45.201867 10154 net.cpp:167] relu2 needs backward computation.
I0413 21:38:45.201870 10154 net.cpp:167] conv2 needs backward computation.
I0413 21:38:45.201874 10154 net.cpp:167] norm1 needs backward computation.
I0413 21:38:45.201876 10154 net.cpp:167] pool1 needs backward computation.
I0413 21:38:45.201879 10154 net.cpp:167] relu1 needs backward computation.
I0413 21:38:45.201882 10154 net.cpp:167] conv1 needs backward computation.
I0413 21:38:45.201895 10154 net.cpp:169] data does not need backward computation.
I0413 21:38:45.201899 10154 net.cpp:205] This network produces output loss
I0413 21:38:45.201915 10154 net.cpp:447] Collecting Learning Rate and Weight Decay.
I0413 21:38:45.201925 10154 net.cpp:217] Network initialization done.
I0413 21:38:45.201927 10154 net.cpp:218] Memory required for data: 3275148
I0413 21:38:45.202579 10154 solver.cpp:154] Creating test net (#0) specified by net file: ./examples/sum_layer_debug/lsp_train_val.prototxt
I0413 21:38:45.202653 10154 net.cpp:257] The NetState phase (1) differed from the phase (0) specified by a rule in layer data
I0413 21:38:45.202911 10154 net.cpp:42] Initializing net from parameters: 
name: "TrainValNet"
state {
  phase: TEST
}
layer {
  name: "data"
  type: "Data"
  top: "data"
  top: "label"
  include {
    phase: TEST
  }
  transform_param {
    mirror: false
    mean_value: 128
    mean_value: 128
    mean_value: 128
  }
  data_param {
    source: "/home/wyang/Data/Code/pose/chen_nips14_full/cache/lsp-03-06/LMDB_val"
    batch_size: 2
    backend: LMDB
  }
}
layer {
  name: "conv1"
  type: "Convolution"
  bottom: "data"
  top: "conv1"
  param {
    lr_mult: 1
    decay_mult: 1
  }
  param {
    lr_mult: 2
    decay_mult: 0
  }
  convolution_param {
    num_output: 48
    pad: 2
    kernel_size: 5
    stride: 1
    weight_filler {
      type: "gaussian"
      std: 0.01
    }
    bias_filler {
      type: "constant"
      value: 0
    }
  }
}
layer {
  name: "relu1"
  type: "ReLU"
  bottom: "conv1"
  top: "conv1"
}
layer {
  name: "pool1"
  type: "Pooling"
  bottom: "conv1"
  top: "pool1"
  pooling_param {
    pool: MAX
    kernel_size: 3
    stride: 2
  }
}
layer {
  name: "norm1"
  type: "LRN"
  bottom: "pool1"
  top: "norm1"
  lrn_param {
    local_size: 5
    alpha: 0.0001
    beta: 0.75
  }
}
layer {
  name: "conv2"
  type: "Convolution"
  bottom: "norm1"
  top: "conv2"
  param {
    lr_mult: 1
    decay_mult: 1
  }
  param {
    lr_mult: 2
    decay_mult: 0
  }
  convolution_param {
    num_output: 128
    pad: 1
    kernel_size: 3
    stride: 1
    weight_filler {
      type: "gaussian"
      std: 0.01
    }
    bias_filler {
      type: "constant"
      value: 1
    }
  }
}
layer {
  name: "relu2"
  type: "ReLU"
  bottom: "conv2"
  top: "conv2"
}
layer {
  name: "pool2"
  type: "Pooling"
  bottom: "conv2"
  top: "pool2"
  pooling_param {
    pool: MAX
    kernel_size: 3
    stride: 2
  }
}
layer {
  name: "norm2"
  type: "LRN"
  bottom: "pool2"
  top: "norm2"
  lrn_param {
    local_size: 5
    alpha: 0.0001
    beta: 0.75
  }
}
layer {
  name: "conv3"
  type: "Convolution"
  bottom: "norm2"
  top: "conv3"
  param {
    lr_mult: 1
    decay_mult: 1
  }
  param {
    lr_mult: 2
    decay_mult: 0
  }
  convolution_param {
    num_output: 128
    pad: 1
    kernel_size: 3
    stride: 1
    weight_filler {
      type: "gaussian"
      std: 0.01
    }
    bias_filler {
      type: "constant"
      value: 1
    }
  }
}
layer {
  name: "relu3"
  type: "ReLU"
  bottom: "conv3"
  top: "conv3"
}
layer {
  name: "conv4"
  type: "Convolution"
  bottom: "conv3"
  top: "conv4"
  param {
    lr_mult: 1
    decay_mult: 1
  }
  param {
    lr_mult: 2
    decay_mult: 0
  }
  convolution_param {
    num_output: 128
    pad: 1
    kernel_size: 3
    stride: 1
    weight_filler {
      type: "gaussian"
      std: 0.01
    }
    bias_filler {
      type: "constant"
      value: 1
    }
  }
}
layer {
  name: "relu4"
  type: "ReLU"
  bottom: "conv4"
  top: "conv4"
}
layer {
  name: "conv5"
  type: "Convolution"
  bottom: "conv4"
  top: "conv5"
  param {
    lr_mult: 1
    decay_mult: 1
  }
  param {
    lr_mult: 2
    decay_mult: 0
  }
  convolution_param {
    num_output: 128
    pad: 1
    kernel_size: 3
    stride: 1
    weight_filler {
      type: "gaussian"
      std: 0.01
    }
    bias_filler {
      type: "constant"
      value: 1
    }
  }
}
layer {
  name: "relu5"
  type: "ReLU"
  bottom: "conv5"
  top: "conv5"
}
layer {
  name: "fc6-conv"
  type: "Convolution"
  bottom: "conv5"
  top: "fc6-conv"
  param {
    lr_mult: 1
    decay_mult: 1
  }
  param {
    lr_mult: 2
    decay_mult: 0
  }
  convolution_param {
    num_output: 4096
    pad: 0
    kernel_size: 9
    stride: 1
  }
}
layer {
  name: "relu6"
  type: "ReLU"
  bottom: "fc6-conv"
  top: "fc6-conv"
}
layer {
  name: "drop6"
  type: "Dropout"
  bottom: "fc6-conv"
  top: "fc6-conv"
  dropout_param {
    dropout_ratio: 0.5
  }
}
layer {
  name: "fc7-conv"
  type: "Convolution"
  bottom: "fc6-conv"
  top: "fc7-conv"
  param {
    lr_mult: 1
    decay_mult: 1
  }
  param {
    lr_mult: 2
    decay_mult: 0
  }
  convolution_param {
    num_output: 4096
    pad: 0
    kernel_size: 1
    stride: 1
  }
}
layer {
  name: "relu7"
  type: "ReLU"
  bottom: "fc7-conv"
  top: "fc7-conv"
}
layer {
  name: "drop7"
  type: "Dropout"
  bottom: "fc7-conv"
  top: "fc7-conv"
  dropout_param {
    dropout_ratio: 0.5
  }
}
layer {
  name: "fc8-conv"
  type: "Convolution"
  bottom: "fc7-conv"
  top: "fc8-conv"
  param {
    lr_mult: 1
    decay_mult: 1
  }
  param {
    lr_mult: 2
    decay_mult: 0
  }
  convolution_param {
    num_output: 9699
    pad: 0
    kernel_size: 1
    stride: 1
  }
}
layer {
  name: "prob"
  type: "Softmax"
  bottom: "fc8-conv"
  top: "prob"
}
layer {
  name: "unary"
  type: "Sum"
  bottom: "prob"
  top: "unary"
  sum_param {
    source: "/home/wyang/Data/Code/iccv/chen-nips14-pose-dev/global_ids.txt"
    mix_num: 13
    parents: 0
    parents: 1
    parents: 2
    parents: 3
    parents: 4
    parents: 5
    parents: 6
    parents: 3
    parents: 8
    parents: 9
    parents: 10
    parents: 11
    parents: 12
    parents: 13
    parents: 2
    parents: 15
    parents: 16
    parents: 17
    parents: 18
    parents: 15
    parents: 20
    parents: 21
    parents: 22
    parents: 23
    parents: 24
    parents: 25
  }
}
layer {
  name: "unary-silence"
  type: "Silence"
  bottom: "unary"
}
layer {
  name: "idpr"
  type: "Idpr"
  bottom: "prob"
  top: "idpr"
  sum_param {
    mix_num: 13
    parents: 0
    parents: 1
    parents: 2
    parents: 3
    parents: 4
    parents: 5
    parents: 6
    parents: 3
    parents: 8
    parents: 9
    parents: 10
    parents: 11
    parents: 12
    parents: 13
    parents: 2
    parents: 15
    parents: 16
    parents: 17
    parents: 18
    parents: 15
    parents: 20
    parents: 21
    parents: 22
    parents: 23
    parents: 24
    parents: 25
  }
}
layer {
  name: "logidpr"
  type: "Logarithm"
  bottom: "idpr"
  top: "idpr"
}
layer {
  name: "idpr-silence"
  type: "Silence"
  bottom: "idpr"
}
layer {
  name: "accuracy"
  type: "Accuracy"
  bottom: "fc8-conv"
  bottom: "label"
  top: "accuracy"
  include {
    phase: TEST
  }
}
layer {
  name: "loss"
  type: "SoftmaxWithLoss"
  bottom: "fc8-conv"
  bottom: "label"
  top: "loss"
}
I0413 21:38:45.203086 10154 layer_factory.hpp:74] Creating layer data
I0413 21:38:45.203100 10154 net.cpp:84] Creating Layer data
I0413 21:38:45.203107 10154 net.cpp:338] data -> data
I0413 21:38:45.203119 10154 net.cpp:338] data -> label
I0413 21:38:45.203129 10154 net.cpp:113] Setting up data
I0413 21:38:45.216294 10154 db.cpp:34] Opened lmdb /home/wyang/Data/Code/pose/chen_nips14_full/cache/lsp-03-06/LMDB_val
I0413 21:38:45.219244 10154 data_layer.cpp:67] output data size: 2,3,36,36
I0413 21:38:45.219329 10154 net.cpp:120] Top shape: 2 3 36 36 (7776)
I0413 21:38:45.219347 10154 net.cpp:120] Top shape: 2 (2)
I0413 21:38:45.219351 10154 layer_factory.hpp:74] Creating layer label_data_1_split
I0413 21:38:45.219367 10154 net.cpp:84] Creating Layer label_data_1_split
I0413 21:38:45.219372 10154 net.cpp:380] label_data_1_split <- label
I0413 21:38:45.219388 10154 net.cpp:338] label_data_1_split -> label_data_1_split_0
I0413 21:38:45.219418 10154 net.cpp:338] label_data_1_split -> label_data_1_split_1
I0413 21:38:45.219429 10154 net.cpp:113] Setting up label_data_1_split
I0413 21:38:45.219434 10154 net.cpp:120] Top shape: 2 (2)
I0413 21:38:45.219437 10154 net.cpp:120] Top shape: 2 (2)
I0413 21:38:45.219440 10154 layer_factory.hpp:74] Creating layer conv1
I0413 21:38:45.219449 10154 net.cpp:84] Creating Layer conv1
I0413 21:38:45.219462 10154 net.cpp:380] conv1 <- data
I0413 21:38:45.219467 10154 net.cpp:338] conv1 -> conv1
I0413 21:38:45.219472 10154 net.cpp:113] Setting up conv1
I0413 21:38:45.219591 10154 net.cpp:120] Top shape: 2 48 36 36 (124416)
I0413 21:38:45.219599 10154 layer_factory.hpp:74] Creating layer relu1
I0413 21:38:45.219605 10154 net.cpp:84] Creating Layer relu1
I0413 21:38:45.219609 10154 net.cpp:380] relu1 <- conv1
I0413 21:38:45.219612 10154 net.cpp:327] relu1 -> conv1 (in-place)
I0413 21:38:45.219627 10154 net.cpp:113] Setting up relu1
I0413 21:38:45.219631 10154 net.cpp:120] Top shape: 2 48 36 36 (124416)
I0413 21:38:45.219635 10154 layer_factory.hpp:74] Creating layer pool1
I0413 21:38:45.219640 10154 net.cpp:84] Creating Layer pool1
I0413 21:38:45.219643 10154 net.cpp:380] pool1 <- conv1
I0413 21:38:45.219647 10154 net.cpp:338] pool1 -> pool1
I0413 21:38:45.219651 10154 net.cpp:113] Setting up pool1
I0413 21:38:45.219658 10154 net.cpp:120] Top shape: 2 48 18 18 (31104)
I0413 21:38:45.219661 10154 layer_factory.hpp:74] Creating layer norm1
I0413 21:38:45.219666 10154 net.cpp:84] Creating Layer norm1
I0413 21:38:45.219668 10154 net.cpp:380] norm1 <- pool1
I0413 21:38:45.219673 10154 net.cpp:338] norm1 -> norm1
I0413 21:38:45.219678 10154 net.cpp:113] Setting up norm1
I0413 21:38:45.219683 10154 net.cpp:120] Top shape: 2 48 18 18 (31104)
I0413 21:38:45.219686 10154 layer_factory.hpp:74] Creating layer conv2
I0413 21:38:45.219691 10154 net.cpp:84] Creating Layer conv2
I0413 21:38:45.219694 10154 net.cpp:380] conv2 <- norm1
I0413 21:38:45.219698 10154 net.cpp:338] conv2 -> conv2
I0413 21:38:45.219703 10154 net.cpp:113] Setting up conv2
I0413 21:38:45.221215 10154 net.cpp:120] Top shape: 2 128 18 18 (82944)
I0413 21:38:45.221225 10154 layer_factory.hpp:74] Creating layer relu2
I0413 21:38:45.221230 10154 net.cpp:84] Creating Layer relu2
I0413 21:38:45.221235 10154 net.cpp:380] relu2 <- conv2
I0413 21:38:45.221238 10154 net.cpp:327] relu2 -> conv2 (in-place)
I0413 21:38:45.221242 10154 net.cpp:113] Setting up relu2
I0413 21:38:45.221246 10154 net.cpp:120] Top shape: 2 128 18 18 (82944)
I0413 21:38:45.221249 10154 layer_factory.hpp:74] Creating layer pool2
I0413 21:38:45.221256 10154 net.cpp:84] Creating Layer pool2
I0413 21:38:45.221268 10154 net.cpp:380] pool2 <- conv2
I0413 21:38:45.221273 10154 net.cpp:338] pool2 -> pool2
I0413 21:38:45.221278 10154 net.cpp:113] Setting up pool2
I0413 21:38:45.221284 10154 net.cpp:120] Top shape: 2 128 9 9 (20736)
I0413 21:38:45.221287 10154 layer_factory.hpp:74] Creating layer norm2
I0413 21:38:45.221292 10154 net.cpp:84] Creating Layer norm2
I0413 21:38:45.221295 10154 net.cpp:380] norm2 <- pool2
I0413 21:38:45.221299 10154 net.cpp:338] norm2 -> norm2
I0413 21:38:45.221318 10154 net.cpp:113] Setting up norm2
I0413 21:38:45.221323 10154 net.cpp:120] Top shape: 2 128 9 9 (20736)
I0413 21:38:45.221326 10154 layer_factory.hpp:74] Creating layer conv3
I0413 21:38:45.221333 10154 net.cpp:84] Creating Layer conv3
I0413 21:38:45.221336 10154 net.cpp:380] conv3 <- norm2
I0413 21:38:45.221341 10154 net.cpp:338] conv3 -> conv3
I0413 21:38:45.221348 10154 net.cpp:113] Setting up conv3
I0413 21:38:45.225160 10154 net.cpp:120] Top shape: 2 128 9 9 (20736)
I0413 21:38:45.225169 10154 layer_factory.hpp:74] Creating layer relu3
I0413 21:38:45.225174 10154 net.cpp:84] Creating Layer relu3
I0413 21:38:45.225178 10154 net.cpp:380] relu3 <- conv3
I0413 21:38:45.225183 10154 net.cpp:327] relu3 -> conv3 (in-place)
I0413 21:38:45.225186 10154 net.cpp:113] Setting up relu3
I0413 21:38:45.225190 10154 net.cpp:120] Top shape: 2 128 9 9 (20736)
I0413 21:38:45.225193 10154 layer_factory.hpp:74] Creating layer conv4
I0413 21:38:45.225198 10154 net.cpp:84] Creating Layer conv4
I0413 21:38:45.225214 10154 net.cpp:380] conv4 <- conv3
I0413 21:38:45.225217 10154 net.cpp:338] conv4 -> conv4
I0413 21:38:45.225224 10154 net.cpp:113] Setting up conv4
I0413 21:38:45.229094 10154 net.cpp:120] Top shape: 2 128 9 9 (20736)
I0413 21:38:45.229104 10154 layer_factory.hpp:74] Creating layer relu4
I0413 21:38:45.229109 10154 net.cpp:84] Creating Layer relu4
I0413 21:38:45.229111 10154 net.cpp:380] relu4 <- conv4
I0413 21:38:45.229117 10154 net.cpp:327] relu4 -> conv4 (in-place)
I0413 21:38:45.229122 10154 net.cpp:113] Setting up relu4
I0413 21:38:45.229126 10154 net.cpp:120] Top shape: 2 128 9 9 (20736)
I0413 21:38:45.229130 10154 layer_factory.hpp:74] Creating layer conv5
I0413 21:38:45.229135 10154 net.cpp:84] Creating Layer conv5
I0413 21:38:45.229147 10154 net.cpp:380] conv5 <- conv4
I0413 21:38:45.229151 10154 net.cpp:338] conv5 -> conv5
I0413 21:38:45.229166 10154 net.cpp:113] Setting up conv5
I0413 21:38:45.233007 10154 net.cpp:120] Top shape: 2 128 9 9 (20736)
I0413 21:38:45.233018 10154 layer_factory.hpp:74] Creating layer relu5
I0413 21:38:45.233024 10154 net.cpp:84] Creating Layer relu5
I0413 21:38:45.233027 10154 net.cpp:380] relu5 <- conv5
I0413 21:38:45.233031 10154 net.cpp:327] relu5 -> conv5 (in-place)
I0413 21:38:45.233036 10154 net.cpp:113] Setting up relu5
I0413 21:38:45.233041 10154 net.cpp:120] Top shape: 2 128 9 9 (20736)
I0413 21:38:45.233043 10154 layer_factory.hpp:74] Creating layer fc6-conv
I0413 21:38:45.233060 10154 net.cpp:84] Creating Layer fc6-conv
I0413 21:38:45.233063 10154 net.cpp:380] fc6-conv <- conv5
I0413 21:38:45.233067 10154 net.cpp:338] fc6-conv -> fc6-conv
I0413 21:38:45.233073 10154 net.cpp:113] Setting up fc6-conv
I0413 21:38:45.265627 10154 net.cpp:120] Top shape: 2 4096 1 1 (8192)
I0413 21:38:45.265657 10154 layer_factory.hpp:74] Creating layer relu6
I0413 21:38:45.265666 10154 net.cpp:84] Creating Layer relu6
I0413 21:38:45.265671 10154 net.cpp:380] relu6 <- fc6-conv
I0413 21:38:45.265676 10154 net.cpp:327] relu6 -> fc6-conv (in-place)
I0413 21:38:45.265683 10154 net.cpp:113] Setting up relu6
I0413 21:38:45.265688 10154 net.cpp:120] Top shape: 2 4096 1 1 (8192)
I0413 21:38:45.265702 10154 layer_factory.hpp:74] Creating layer drop6
I0413 21:38:45.265710 10154 net.cpp:84] Creating Layer drop6
I0413 21:38:45.265713 10154 net.cpp:380] drop6 <- fc6-conv
I0413 21:38:45.265717 10154 net.cpp:327] drop6 -> fc6-conv (in-place)
I0413 21:38:45.265722 10154 net.cpp:113] Setting up drop6
I0413 21:38:45.265727 10154 net.cpp:120] Top shape: 2 4096 1 1 (8192)
I0413 21:38:45.265730 10154 layer_factory.hpp:74] Creating layer fc7-conv
I0413 21:38:45.265736 10154 net.cpp:84] Creating Layer fc7-conv
I0413 21:38:45.265739 10154 net.cpp:380] fc7-conv <- fc6-conv
I0413 21:38:45.265745 10154 net.cpp:338] fc7-conv -> fc7-conv
I0413 21:38:45.265751 10154 net.cpp:113] Setting up fc7-conv
I0413 21:38:45.279872 10154 net.cpp:120] Top shape: 2 4096 1 1 (8192)
I0413 21:38:45.279909 10154 layer_factory.hpp:74] Creating layer relu7
I0413 21:38:45.279932 10154 net.cpp:84] Creating Layer relu7
I0413 21:38:45.279971 10154 net.cpp:380] relu7 <- fc7-conv
I0413 21:38:45.279991 10154 net.cpp:327] relu7 -> fc7-conv (in-place)
I0413 21:38:45.280001 10154 net.cpp:113] Setting up relu7
I0413 21:38:45.280009 10154 net.cpp:120] Top shape: 2 4096 1 1 (8192)
I0413 21:38:45.280015 10154 layer_factory.hpp:74] Creating layer drop7
I0413 21:38:45.280025 10154 net.cpp:84] Creating Layer drop7
I0413 21:38:45.280030 10154 net.cpp:380] drop7 <- fc7-conv
I0413 21:38:45.280048 10154 net.cpp:327] drop7 -> fc7-conv (in-place)
I0413 21:38:45.280066 10154 net.cpp:113] Setting up drop7
I0413 21:38:45.280081 10154 net.cpp:120] Top shape: 2 4096 1 1 (8192)
I0413 21:38:45.280088 10154 layer_factory.hpp:74] Creating layer fc8-conv
I0413 21:38:45.280097 10154 net.cpp:84] Creating Layer fc8-conv
I0413 21:38:45.280103 10154 net.cpp:380] fc8-conv <- fc7-conv
I0413 21:38:45.280110 10154 net.cpp:338] fc8-conv -> fc8-conv
I0413 21:38:45.280119 10154 net.cpp:113] Setting up fc8-conv
I0413 21:38:45.310920 10154 net.cpp:120] Top shape: 2 9699 1 1 (19398)
I0413 21:38:45.310950 10154 layer_factory.hpp:74] Creating layer fc8-conv_fc8-conv_0_split
I0413 21:38:45.310958 10154 net.cpp:84] Creating Layer fc8-conv_fc8-conv_0_split
I0413 21:38:45.310962 10154 net.cpp:380] fc8-conv_fc8-conv_0_split <- fc8-conv
I0413 21:38:45.310971 10154 net.cpp:338] fc8-conv_fc8-conv_0_split -> fc8-conv_fc8-conv_0_split_0
I0413 21:38:45.310982 10154 net.cpp:338] fc8-conv_fc8-conv_0_split -> fc8-conv_fc8-conv_0_split_1
I0413 21:38:45.310991 10154 net.cpp:338] fc8-conv_fc8-conv_0_split -> fc8-conv_fc8-conv_0_split_2
I0413 21:38:45.310997 10154 net.cpp:113] Setting up fc8-conv_fc8-conv_0_split
I0413 21:38:45.311017 10154 net.cpp:120] Top shape: 2 9699 1 1 (19398)
I0413 21:38:45.311031 10154 net.cpp:120] Top shape: 2 9699 1 1 (19398)
I0413 21:38:45.311036 10154 net.cpp:120] Top shape: 2 9699 1 1 (19398)
I0413 21:38:45.311041 10154 layer_factory.hpp:74] Creating layer prob
I0413 21:38:45.311050 10154 net.cpp:84] Creating Layer prob
I0413 21:38:45.311060 10154 net.cpp:380] prob <- fc8-conv_fc8-conv_0_split_0
I0413 21:38:45.311069 10154 net.cpp:338] prob -> prob
I0413 21:38:45.311086 10154 net.cpp:113] Setting up prob
I0413 21:38:45.311120 10154 net.cpp:120] Top shape: 2 9699 1 1 (19398)
I0413 21:38:45.311126 10154 layer_factory.hpp:74] Creating layer prob_prob_0_split
I0413 21:38:45.311132 10154 net.cpp:84] Creating Layer prob_prob_0_split
I0413 21:38:45.311148 10154 net.cpp:380] prob_prob_0_split <- prob
I0413 21:38:45.311166 10154 net.cpp:338] prob_prob_0_split -> prob_prob_0_split_0
I0413 21:38:45.311174 10154 net.cpp:338] prob_prob_0_split -> prob_prob_0_split_1
I0413 21:38:45.311183 10154 net.cpp:113] Setting up prob_prob_0_split
I0413 21:38:45.311192 10154 net.cpp:120] Top shape: 2 9699 1 1 (19398)
I0413 21:38:45.311199 10154 net.cpp:120] Top shape: 2 9699 1 1 (19398)
I0413 21:38:45.311204 10154 layer_factory.hpp:74] Creating layer unary
I0413 21:38:45.311215 10154 net.cpp:84] Creating Layer unary
I0413 21:38:45.311221 10154 net.cpp:380] unary <- prob_prob_0_split_0
I0413 21:38:45.311230 10154 net.cpp:338] unary -> unary
I0413 21:38:45.311239 10154 net.cpp:113] Setting up unary
I0413 21:38:45.311524 10154 net.cpp:120] Top shape: 2 26 1 1 (52)
I0413 21:38:45.311530 10154 layer_factory.hpp:74] Creating layer unary-silence
I0413 21:38:45.311537 10154 net.cpp:84] Creating Layer unary-silence
I0413 21:38:45.311552 10154 net.cpp:380] unary-silence <- unary
I0413 21:38:45.311558 10154 net.cpp:113] Setting up unary-silence
I0413 21:38:45.311563 10154 layer_factory.hpp:74] Creating layer idpr
I0413 21:38:45.311573 10154 net.cpp:84] Creating Layer idpr
I0413 21:38:45.311580 10154 net.cpp:380] idpr <- prob_prob_0_split_1
I0413 21:38:45.311588 10154 net.cpp:338] idpr -> idpr
I0413 21:38:45.311596 10154 net.cpp:113] Setting up idpr
I0413 21:38:45.312552 10154 net.cpp:120] Top shape: 2 650 1 1 (1300)
I0413 21:38:45.312561 10154 layer_factory.hpp:74] Creating layer logidpr
I0413 21:38:45.312567 10154 net.cpp:84] Creating Layer logidpr
I0413 21:38:45.312584 10154 net.cpp:380] logidpr <- idpr
I0413 21:38:45.312608 10154 net.cpp:327] logidpr -> idpr (in-place)
I0413 21:38:45.312618 10154 net.cpp:113] Setting up logidpr
I0413 21:38:45.312626 10154 net.cpp:120] Top shape: 2 650 1 1 (1300)
I0413 21:38:45.312633 10154 layer_factory.hpp:74] Creating layer idpr-silence
I0413 21:38:45.312640 10154 net.cpp:84] Creating Layer idpr-silence
I0413 21:38:45.312646 10154 net.cpp:380] idpr-silence <- idpr
I0413 21:38:45.312652 10154 net.cpp:113] Setting up idpr-silence
I0413 21:38:45.312659 10154 layer_factory.hpp:74] Creating layer accuracy
I0413 21:38:45.312666 10154 net.cpp:84] Creating Layer accuracy
I0413 21:38:45.312674 10154 net.cpp:380] accuracy <- fc8-conv_fc8-conv_0_split_1
I0413 21:38:45.312680 10154 net.cpp:380] accuracy <- label_data_1_split_0
I0413 21:38:45.312687 10154 net.cpp:338] accuracy -> accuracy
I0413 21:38:45.312696 10154 net.cpp:113] Setting up accuracy
I0413 21:38:45.312711 10154 net.cpp:120] Top shape: (1)
I0413 21:38:45.312717 10154 layer_factory.hpp:74] Creating layer loss
I0413 21:38:45.312728 10154 net.cpp:84] Creating Layer loss
I0413 21:38:45.312734 10154 net.cpp:380] loss <- fc8-conv_fc8-conv_0_split_2
I0413 21:38:45.312741 10154 net.cpp:380] loss <- label_data_1_split_1
I0413 21:38:45.312750 10154 net.cpp:338] loss -> loss
I0413 21:38:45.312757 10154 net.cpp:113] Setting up loss
I0413 21:38:45.312762 10154 layer_factory.hpp:74] Creating layer loss
I0413 21:38:45.312815 10154 net.cpp:120] Top shape: (1)
I0413 21:38:45.312819 10154 net.cpp:122]     with loss weight 1
I0413 21:38:45.312827 10154 net.cpp:167] loss needs backward computation.
I0413 21:38:45.312831 10154 net.cpp:169] accuracy does not need backward computation.
I0413 21:38:45.312834 10154 net.cpp:169] idpr-silence does not need backward computation.
I0413 21:38:45.312837 10154 net.cpp:169] logidpr does not need backward computation.
I0413 21:38:45.312839 10154 net.cpp:169] idpr does not need backward computation.
I0413 21:38:45.312842 10154 net.cpp:169] unary-silence does not need backward computation.
I0413 21:38:45.312844 10154 net.cpp:169] unary does not need backward computation.
I0413 21:38:45.312847 10154 net.cpp:169] prob_prob_0_split does not need backward computation.
I0413 21:38:45.312850 10154 net.cpp:169] prob does not need backward computation.
I0413 21:38:45.312854 10154 net.cpp:167] fc8-conv_fc8-conv_0_split needs backward computation.
I0413 21:38:45.312855 10154 net.cpp:167] fc8-conv needs backward computation.
I0413 21:38:45.312858 10154 net.cpp:167] drop7 needs backward computation.
I0413 21:38:45.312861 10154 net.cpp:167] relu7 needs backward computation.
I0413 21:38:45.312865 10154 net.cpp:167] fc7-conv needs backward computation.
I0413 21:38:45.312867 10154 net.cpp:167] drop6 needs backward computation.
I0413 21:38:45.312870 10154 net.cpp:167] relu6 needs backward computation.
I0413 21:38:45.312872 10154 net.cpp:167] fc6-conv needs backward computation.
I0413 21:38:45.312875 10154 net.cpp:167] relu5 needs backward computation.
I0413 21:38:45.312878 10154 net.cpp:167] conv5 needs backward computation.
I0413 21:38:45.312881 10154 net.cpp:167] relu4 needs backward computation.
I0413 21:38:45.312885 10154 net.cpp:167] conv4 needs backward computation.
I0413 21:38:45.312886 10154 net.cpp:167] relu3 needs backward computation.
I0413 21:38:45.312890 10154 net.cpp:167] conv3 needs backward computation.
I0413 21:38:45.312892 10154 net.cpp:167] norm2 needs backward computation.
I0413 21:38:45.312896 10154 net.cpp:167] pool2 needs backward computation.
I0413 21:38:45.312898 10154 net.cpp:167] relu2 needs backward computation.
I0413 21:38:45.312901 10154 net.cpp:167] conv2 needs backward computation.
I0413 21:38:45.312904 10154 net.cpp:167] norm1 needs backward computation.
I0413 21:38:45.312907 10154 net.cpp:167] pool1 needs backward computation.
I0413 21:38:45.312911 10154 net.cpp:167] relu1 needs backward computation.
I0413 21:38:45.312913 10154 net.cpp:167] conv1 needs backward computation.
I0413 21:38:45.312916 10154 net.cpp:169] label_data_1_split does not need backward computation.
I0413 21:38:45.312921 10154 net.cpp:169] data does not need backward computation.
I0413 21:38:45.312929 10154 net.cpp:205] This network produces output accuracy
I0413 21:38:45.312932 10154 net.cpp:205] This network produces output loss
I0413 21:38:45.312948 10154 net.cpp:447] Collecting Learning Rate and Weight Decay.
I0413 21:38:45.312957 10154 net.cpp:217] Network initialization done.
I0413 21:38:45.312960 10154 net.cpp:218] Memory required for data: 3352760
I0413 21:38:45.313046 10154 solver.cpp:42] Solver scaffolding done.
I0413 21:38:45.313081 10154 caffe.cpp:86] Finetuning from /home/wyang/Data/Code/pose/chen_nips14_full/cache/lsp-03-06/fully_conv_net_by_net_surgery.caffemodel
E0413 21:38:47.739087 10154 upgrade_proto.cpp:618] Attempting to upgrade input file specified using deprecated V1LayerParameter: /home/wyang/Data/Code/pose/chen_nips14_full/cache/lsp-03-06/fully_conv_net_by_net_surgery.caffemodel
I0413 21:38:47.917502 10154 upgrade_proto.cpp:626] Successfully upgraded file specified using deprecated V1LayerParameter
E0413 21:38:48.421231 10154 upgrade_proto.cpp:618] Attempting to upgrade input file specified using deprecated V1LayerParameter: /home/wyang/Data/Code/pose/chen_nips14_full/cache/lsp-03-06/fully_conv_net_by_net_surgery.caffemodel
I0413 21:38:48.593428 10154 upgrade_proto.cpp:626] Successfully upgraded file specified using deprecated V1LayerParameter
I0413 21:38:48.657212 10154 solver.cpp:222] Solving TrainValNet
I0413 21:38:48.657238 10154 solver.cpp:223] Learning Rate Policy: step
I0413 21:38:48.657245 10154 solver.cpp:266] Iteration 0, Testing net (#0)
I0413 21:38:48.738508 10154 solver.cpp:315]     Test net output #0: accuracy = 1
I0413 21:38:48.738538 10154 solver.cpp:315]     Test net output #1: loss = 0.300615 (* 1 = 0.300615 loss)
I0413 21:38:48.770068 10154 solver.cpp:189] Iteration 0, loss = 0.396194
I0413 21:38:48.770090 10154 solver.cpp:204]     Train net output #0: loss = 0.396194 (* 1 = 0.396194 loss)
I0413 21:38:48.770103 10154 solver.cpp:464] Iteration 0, lr = 0.005
I0413 21:38:49.374038 10154 solver.cpp:189] Iteration 10, loss = 87.3365
I0413 21:38:49.374063 10154 solver.cpp:204]     Train net output #0: loss = 87.3365 (* 1 = 87.3365 loss)
I0413 21:38:49.374068 10154 solver.cpp:464] Iteration 10, lr = 0.005
I0413 21:38:49.957667 10154 solver.cpp:189] Iteration 20, loss = 87.3365
I0413 21:38:49.957717 10154 solver.cpp:204]     Train net output #0: loss = 87.3365 (* 1 = 87.3365 loss)
I0413 21:38:49.957726 10154 solver.cpp:464] Iteration 20, lr = 0.005
I0413 21:38:50.540879 10154 solver.cpp:189] Iteration 30, loss = 87.3365
I0413 21:38:50.540901 10154 solver.cpp:204]     Train net output #0: loss = 87.3365 (* 1 = 87.3365 loss)
I0413 21:38:50.540906 10154 solver.cpp:464] Iteration 30, lr = 0.005
I0413 21:38:51.124508 10154 solver.cpp:189] Iteration 40, loss = 87.3365
I0413 21:38:51.124532 10154 solver.cpp:204]     Train net output #0: loss = 87.3365 (* 1 = 87.3365 loss)
I0413 21:38:51.124537 10154 solver.cpp:464] Iteration 40, lr = 0.005
I0413 21:38:51.708019 10154 solver.cpp:189] Iteration 50, loss = 87.3365
I0413 21:38:51.708053 10154 solver.cpp:204]     Train net output #0: loss = 87.3365 (* 1 = 87.3365 loss)
I0413 21:38:51.708060 10154 solver.cpp:464] Iteration 50, lr = 0.005
